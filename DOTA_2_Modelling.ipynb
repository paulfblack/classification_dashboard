{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defense of the Ancients 2 Outcome Prediction Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics\n",
    "from copy import deepcopy\n",
    "from sqlalchemy import create_engine\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFORMATION ON DATASETS PROVIDED BY KAGGLE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**matches: **contains top level information about each match. see https://wiki.teamfortress.com/wiki/WebAPI/GetMatchDetails#Tower_Status%22tower_status_dire%22:%202047) for interpreting tower and barracks status. Cluster can link matches to geographic region.  \n",
    "**players:** Individual players are identified by account_id but there is an option to play anonymously and roughly one third of the account_id are not available. Anonymous users have the value of 0 for account_id. Contains totals for kills, deaths, denies, etc. Player action counts are available, and are indicated by variable names beginning with unit_order_. Counts for reasons for acquiring or losing gold, and gaining experience, have prefixes gold_, and xp_.  \n",
    "**player_time:** Contains last hits, experience, and gold sampled at one minute interval for all players in all matches. The column names indicate the player_slot. For instance xp_t_1 indicates that this column has experience sums for the player in slot one.  \n",
    "**teamfights:** Start and stop time of teamfights, as well as last death time. Teamfights appear to be all battles with three or more deaths. As such this does not include all battles for the entire match.  \n",
    "**teamfights_players :** Additional information provided for each player in each teamfight. player_slot can be used to link this back to players.csv\n",
    "objectives: Gives information on all the objectives completed, by which player and at what time.  \n",
    "**chat:** All chat for the 50k matches. There is plenty of profanity, and good natured trolling.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**purchase_log** item purchase times  \n",
    "**ability_upgrade** ability upgrade times and levels \n",
    "  \n",
    "  \n",
    "patch_dates release dates for various patches, use start_time from match.csv to determine which patch a match was played in.  \n",
    "  \n",
    "  \n",
    "ability_ids use with ability_upgrades.csv to get the names of upgraded abilities  \n",
    "item_ids use with purchase_log.csv to get the names of purchased items  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def team_assign(x):\n",
    "    \"\"\"Assigns a team value to each player of either team 0 or team 1\n",
    "    the dataframe identifies each player individually.\n",
    "    team 0 player_ids: 1-5 | team 1 player_ids: 111-115\n",
    "    For data flexibility purposes the teams are internally 0 and 1, but\n",
    "    future column naming conventions with refer to them as team 1 and \n",
    "    team 2 respectively\"\"\"\n",
    "    if x < 100:\n",
    "        y = 0\n",
    "    else:\n",
    "        y = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sum_players(df, column):\n",
    "    \"\"\"Returns the sum of column 'column' for each team in each match as a new column for Dataframe players\"\"\"\n",
    "    temp_df = pd.DataFrame()\n",
    "    # group by match_id and team\n",
    "    temp_df[column] = players.groupby(['match_id','team'])[column].sum()\n",
    "    temp_df = temp_df.reset_index()\n",
    "    # split into two dataframes\n",
    "    temp_df1 = temp_df.query('team == 0')\n",
    "    temp_df2 = temp_df.query('team == 1')\n",
    "    temp_df1.drop('team',axis=1,inplace=True)\n",
    "    temp_df2.drop('team',axis=1,inplace=True)\n",
    "    # merge back to original dataframe with suffixes based on team id.\n",
    "    temp_df = temp_df1.merge(temp_df2, how='left', on='match_id', suffixes = ['_1','_2'])\n",
    "    return df.merge(temp_df, on='match_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_players(df, column):\n",
    "    \"\"\"Returns the mean of column 'column' for each team in each match as a new column for Dataframe players\"\"\"\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[column] = players.groupby(['match_id','team'])[column].mean()\n",
    "    temp_df = temp_df.reset_index()\n",
    "    temp_df1 = temp_df.query('team == 0')\n",
    "    temp_df2 = temp_df.query('team == 1')\n",
    "    temp_df1.drop('team',axis=1,inplace=True)\n",
    "    temp_df2.drop('team',axis=1,inplace=True)\n",
    "    temp_df = temp_df1.merge(temp_df2, how='left', on='match_id', suffixes = ['_1','_2'])\n",
    "    return df.merge(temp_df, on='match_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_std_players(df, column):\n",
    "    \"\"\"Returns the standard deviation of column 'column' for each team in each match as a new column for Dataframe players.\n",
    "    This was not used in the final procduct, but may be picked up later\"\"\"\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[column] = players.groupby(['match_id','team'])[column].std()\n",
    "    temp_df = temp_df.reset_index()\n",
    "    temp_df1 = temp_df.query('team == 0')\n",
    "    temp_df2 = temp_df.query('team == 1')\n",
    "    temp_df1.drop('team',axis=1,inplace=True)\n",
    "    temp_df2.drop('team',axis=1,inplace=True)\n",
    "    temp_df = temp_df1.merge(temp_df2, how='left', on='match_id', suffixes = ['_1','_2'])\n",
    "    return df.merge(temp_df, on='match_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_teamfights(df, column):\n",
    "    \"\"\"Returns the mean of column 'column' for each team for each teamfight in each match as a new column for Dataframe teamfights.\"\"\"\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df2 = pd.DataFrame()\n",
    "    temp_df[column] = teamfights_players.groupby(['match_id','team','team_fight'])[column].mean()\n",
    "    temp_df = temp_df.reset_index()\n",
    "    temp_df2[column] = temp_df.groupby(['match_id','team'])[column].mean()\n",
    "    temp_df2 = temp_df2.reset_index()\n",
    "    temp_df3 = temp_df2.query('team == 0')\n",
    "    temp_df4 = temp_df2.query('team == 1')\n",
    "    temp_df3.drop('team',axis=1,inplace=True)\n",
    "    temp_df4.drop('team',axis=1,inplace=True)\n",
    "    temp_df = temp_df3.merge(temp_df4, how='left', on='match_id', suffixes = ['_1','_2'])\n",
    "    return df.merge(temp_df, on='match_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_std_teamfights(df, column):\n",
    "    \"\"\"Returns the standard deviation of column 'column' for each team for each teamfight in each match as a new column for Dataframe teamfights.\n",
    "    This was not used in the final procduct, but may be picked up later\"\"\"\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df2 = pd.DataFrame()\n",
    "    temp_df[column] = teamfights_players.groupby(['match_id','team','team_fight'])[column].std()\n",
    "    temp_df = temp_df.reset_index()\n",
    "    temp_df2[column] = temp_df.groupby(['match_id','team'])[column].mean()\n",
    "    temp_df2 = temp_df2.reset_index()\n",
    "    temp_df3 = temp_df2.query('team == 0')\n",
    "    temp_df4 = temp_df2.query('team == 1')\n",
    "    temp_df3.drop('team',axis=1,inplace=True)\n",
    "    temp_df4.drop('team',axis=1,inplace=True)\n",
    "    temp_df = temp_df3.merge(temp_df4, how='left', on='match_id', suffixes = ['_1','_2'])\n",
    "    return df.merge(temp_df, on='match_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match Outcome Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "password = os.environ['POSTGRESQL_PASS']\n",
    "ip_address = os.environ['AWS_IP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://ubuntu:%s@%s:5432/' % (password, ip_address))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match = pd.read_sql_query('''SELECT match_id, game_mode, radiant_win FROM match''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teamfights_players = pd.read_sql_query('''SELECT match_id, player_slot, damage FROM teamfights_players''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players = pd.read_sql_query('''SELECT match_id, player_slot, leaver_status, gold_spent, gold, level, xp_per_min, hero_healing, kills, deaths, \\\n",
    "assists FROM players''', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate team column for grouping by player team\n",
    "players['team'] = players['player_slot'].apply(team_assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Switch win status from True False to values 0 and 1 and change name to winner\n",
    "match['winner'] = match['radiant_win'].apply(lambda x: 1 if x == True else 0)\n",
    "match.drop('radiant_win',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check to see if any players left early or were disconnected from the match\n",
    "match['leaver_status'] = players.groupby(['match_id'])['leaver_status'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate individual percentage gold spent by player_id\n",
    "players['gold_spent_percentage'] = players['gold_spent'] / (players['gold'] + players['gold_spent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a list of columns for iterating through and gathering team mean or team sum\n",
    "players_mean_list = ['gold_spent','gold_spent_percentage','level','xp_per_min','hero_healing']\n",
    "players_sum_list = ['kills','deaths','assists']\n",
    "master_col_list = players_mean_list + players_sum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/paul/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/paul/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/paul/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for col_name in players_mean_list:\n",
    "    match = get_mean_players(match, col_name)\n",
    "for col_name in players_sum_list:\n",
    "    match = get_sum_players(match, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert total deaths per team to just environmentally caused deaths\n",
    "match['env_deaths_1'] = match['deaths_1'] - match['kills_2']\n",
    "match['env_deaths_2'] = match['deaths_2'] - match['kills_1']\n",
    "master_col_list.append('env_deaths')\n",
    "master_col_list.remove('deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match['asst_rate_1'] =  match['assists_1'] / match['kills_1']\n",
    "match['asst_rate_2'] =  match['assists_2'] / match['kills_2']\n",
    "\n",
    "match['asst_rate_2'] = match['asst_rate_2'].apply(lambda x: 0.0 if x == np.inf else x)\n",
    "match['asst_rate_1'] = match['asst_rate_1'].apply(lambda x: 0.0 if x == np.inf else x)\n",
    "\n",
    "master_col_list.append('asst_rate')\n",
    "master_col_list.remove('assists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Fights Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teamfights_players['team'] = teamfights_players['player_slot'].apply(team_assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teamfights_players['team_fight'] = [x//10 for x in range(len(teamfights_players))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(x):\n",
    "    \"\"\"Used for determining if a player did or did not cause damage in a team fight as a proxy for participation\"\"\"\n",
    "    if x > 0:\n",
    "        x = 1\n",
    "    else:\n",
    "        x = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teamfights_players['damage'] = teamfights_players['damage'].apply(binarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/paul/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "match = get_mean_teamfights(match, 'damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_col_list.append('damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only look at games in which no players left and the games were ranked\n",
    "match = match.query('leaver_status == 0').query('game_mode == \"22\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match = match.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = match.iloc[:,4:]\n",
    "y = match.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41047, 22)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976938692651\n"
     ]
    }
   ],
   "source": [
    "xscaled = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(xscaled,y,test_size=0.3, random_state=42)\n",
    "rfc = RandomForestClassifier(max_depth=9)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_acc = rfc.score(X_test,y_test)\n",
    "\n",
    "print(rfc_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantage DataFrame and RFC Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For computational speed look at team 1's advantage/disadvantage when compared to team two and reduce 18 features down to 9\n",
    "advantage_df = pd.DataFrame()\n",
    "\n",
    "for col_name in master_col_list:\n",
    "    advantage_df[col_name] = match['%s_%s' % (col_name, '1')] - match['%s_%s' % (col_name, '2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "advantage_df['winner'] = match['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "advantage_df.rename(columns={'damage':'teamfight_participation'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = advantage_df.iloc[:,-1]\n",
    "\n",
    "X = advantage_df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985708485587\n"
     ]
    }
   ],
   "source": [
    "xscaled = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(xscaled,y,test_size=0.3, random_state=42)\n",
    "rfc = RandomForestClassifier(max_depth=9)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_acc = rfc.score(X_test,y_test)\n",
    "\n",
    "print(rfc_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make all combinations of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "# all unique combinations of on/off for features (columns) in x\n",
    "comb_list = list(itertools.product([0, 1], repeat=len(X.iloc[0])))\n",
    "# \n",
    "comb_ind = []\n",
    "\n",
    "for x in comb_list:\n",
    "    indices = [i for i, v in enumerate(x) if v == 1]\n",
    "    comb_ind.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0, 0, 0, 0, 0, 0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# translator for converting binary combiation lists into a unique value \n",
    "base_10_translator = [2**x for x in range(len(X.iloc[0]))]\n",
    "base_10_translator = base_10_translator[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove combination in which no features are used\n",
    "comb_list.remove((0, 0, 0, 0, 0, 0, 0, 0, 0))\n",
    "\n",
    "comb_ind.remove([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate dictionary for holding all of the \n",
    "\n",
    "model_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid Search CV Params \n",
    "max_depth_range = ([5,10,15,20])\n",
    "n_estimators =[50,100,500,1000]\n",
    "param_grid = dict(max_depth=max_depth_range, n_estimators=n_estimators) \n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first pass checking for best params\n",
    "for k, v in enumerate(comb_list):\n",
    "    xscaled = StandardScaler().fit_transform(X.iloc[:,comb_ind[k]])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xscaled,y,test_size=0.3, random_state=42)\n",
    "    grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=param_grid, cv=cv)\n",
    "    grid.fit(X_train, y_train)\n",
    "    y_pred=grid.predict(X_test)\n",
    "    params = grid.best_params_\n",
    "    scores = {}\n",
    "    scores['code'] = np.dot(v, base_10_translator)\n",
    "    scores['accuracy'] = metrics.accuracy_score(y_test,y_pred)\n",
    "    scores['precision'] = metrics.precision_score(y_test,y_pred)\n",
    "    scores['recall'] = metrics.recall_score(y_test,y_pred)\n",
    "    scores['f1_score'] = metrics.f1_score(y_test,y_pred)\n",
    "\n",
    "    model_dict[np.dot(v, base_10_translator)] = dict(scores = scores, params = params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# didn't end up saving best params, but this can be done at a later date with this template\n",
    "df = pd.DataFrame([], columns = ['Group','Scores'])\n",
    "for k,v in enumerate(comb_list):\n",
    "    temp = X.iloc[:,comb_ind[k]]\n",
    "    xscaled = StandardScaler().fit_transform(temp)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xscaled,y,test_size=0.3, random_state=42)\n",
    "    grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=cv)\n",
    "    grid.fit(X_train, y_train)\n",
    "    y_pred=grid.predict(X_test)\n",
    "    df2 = pd.DataFrame([[np.dot(v, base_10_translator), metrics.accuracy_score(y_test,y_pred)],\n",
    "                        [np.dot(v, base_10_translator),metrics.precision_score(y_test,y_pred)],\n",
    "                         [np.dot(v, base_10_translator),metrics.recall_score(y_test,y_pred)],\n",
    "                         [np.dot(v, base_10_translator),metrics.f1_score(y_test,y_pred)]], columns=['Group','Scores'])\n",
    "    df = df.append(df2, ignore_index=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reposition data for vertical bar chart in visualization\n",
    "vbar_df = deepcopy(df)\n",
    "vbar_df['Accuracy'] = vbar_df['Scores']\n",
    "\n",
    "vbar_df['Precision'] = vbar_df['Scores'].shift(-1)\n",
    "\n",
    "vbar_df['Recall'] = vbar_df['Scores'].shift(-2)\n",
    "\n",
    "vbar_df['F1 score'] = vbar_df['Scores'].shift(-3)\n",
    "\n",
    "vbar_df.drop('Scores', axis=1, inplace=True)\n",
    "\n",
    "vbar_df.drop_duplicates('Group', inplace = True)\n",
    "\n",
    "nums = [1,2,4,8,16,32,64,128, 256]\n",
    "\n",
    "vbar_df = vbar_df.query('Group in @nums')\n",
    "\n",
    "vbar_df = vbar_df.reset_index()\n",
    "\n",
    "vbar_df.drop(\"index\", axis=1, inplace = True)\n",
    "\n",
    "vbar_df.to_csv('./viz/vbardata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare data for horizontal bar chart \n",
    "\n",
    "hbar_df = deepcopy(df)\n",
    "\n",
    "hbar_df = hbar_df.groupby(['Group'])['Scores']\n",
    "\n",
    "hbar_df = hbar_df.reset_index()\n",
    "\n",
    "hbar_df.drop(\"index\", axis=1, inplace = True)\n",
    "\n",
    "hbar_df.to_csv('./viz/vbardata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump( model_dict, open( \"model_dict.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Search for best overall combination\n",
    "\n",
    "df['mean'] = (df.Accuracy + df.Precision + df.Recall + df.f1score)/4\n",
    "\n",
    "df['mean'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>384.0</td>\n",
       "      <td>0.985627</td>\n",
       "      <td>0.985564</td>\n",
       "      <td>0.986648</td>\n",
       "      <td>0.986648</td>\n",
       "      <td>0.986122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Group  Accuracy  Precision    Recall   f1score      mean\n",
       "1532  384.0  0.985627   0.985564  0.986648  0.986648  0.986122"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('mean == 0.98612175384788592')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
